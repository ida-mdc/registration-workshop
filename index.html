<!doctype html><html lang=en><head><meta name=generator content="Hugo 0.136.0"><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Image Registration Workshop</title>
<link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Urbanist:wght@300;400;500;700&display=swap"><link rel=stylesheet href=/registration-workshop/css/main.css><link rel=stylesheet href=/registration-workshop/reveal/plugin/highlight/monokai.css><script>function toggleMetadata(e){const t=document.getElementById("metadata-"+e),n=event.target;t.style.display==="none"||t.style.display===""?t.style.display="flex":t.style.display="none"}</script><script>document.addEventListener("DOMContentLoaded",function(){const t=new URLSearchParams(window.location.search),n=t.get("view"),e=document.getElementById("page-content");if(n==="slides"){e.classList.add("reveal"),e.classList.remove("scroll");const n=e=>{const t=document.createElement("link");t.rel="stylesheet",t.href=e,document.head.appendChild(t)},t=(e,t)=>{const n=document.createElement("script");n.src=e,n.onload=t||function(){},document.body.appendChild(n)};n("/registration-workshop/reveal/dist/reveal.css"),n("/registration-workshop/reveal/dist/theme/white-hi.css"),n("/registration-workshop/reveal/plugin/highlight/monokai.css"),t("/registration-workshop/reveal/dist/reveal.js",function(){console.log("Reveal.js loaded"),t("/registration-workshop/reveal/plugin/markdown/markdown.js",function(){t("/registration-workshop/reveal/plugin/highlight/highlight.js",function(){t("/registration-workshop/reveal/plugin/notes/notes.js",function(){console.log("All Reveal.js plugins loaded and ready to initialize."),typeof Reveal!="undefined"?Reveal.initialize({hash:!0,slideNumber:!0,center:!1,disableLayout:!0,transition:"fade",display:"flex",plugins:[RevealMarkdown,RevealHighlight,RevealNotes]}):console.error("Reveal.js is not defined, initialization failed.")})})})})}else e.classList.remove("reveal"),e.classList.add("scroll")})</script><script src=/registration-workshop/js/jquery.min.js></script><script type=text/javascript src=/registration-workshop/js/jquery.qrcode.js></script><script type=text/javascript src=/registration-workshop/js/qrcode.js></script></head><body><div class=workshop id=page-content><div class=reveal-header><a href="?view=slides" class="toggle-view hidden-in-slides">View as Slides</a><div class=hi-icon></div></div><div class="slides limited-width" id=slides-container><section style=background-image:url(/registration-workshop/img/registration.png)><div class=presentation-title><h1>Image Registration Workshop</h1><div class=presenter><div>Ella Bahry</div><div>Sep 24, 2024</div></div><img class=hidden-in-page src=/registration-workshop/img/RZ_211119_Helmholtz-Imaging_Logo_4C_White.png height=90vh><aside class=notes></aside></div></section><section><nav class=toc><h2>Table of Contents</h2><ul><li><a href=#section-0>What is Image Registration?</a></li><li><a href=#section-1>Common needs in research</a></li><li><a href=#section-2>Image Transformation Types</a></li><li><a href=#section-3>Image Interpolation - Reason</a></li><li><a href=#section-4>Image Interpolation - Common Types</a></li><li><a href=#section-5>Image Interpolation Example</a></li><li><a href=#section-6>Image Interpolation - Anti-Aliasing in Down-Sampling</a></li><li><a href=#section-7>Integrated Image Registration Techniques</a></li><li><a href=#section-8>Technique: Intensity Based (Correlation Coefficient)</a></li><li><a href=#section-9>Technique: Mutual Information</a></li><li><a href=#section-10>2 Step Techniques - Feature Detection & Transformation</a></li><li><a href=#section-11>Technique: Feature-Based Registration (SIFT)</a></li><li><a href=#section-12>Technique: Model Based (Pose Estimation)</a></li><li><a href=#section-13>Challenges & Considerations</a></li><li><a href=#section-14>Image Registration Guideline</a></li><li><a href=#section-15>Software Tools for Image Registration</a></li><li><a href=#section-16>Thank You!</a></li></ul></nav></section><section id=section-0><h2 id=what-is-image-registration>What is Image Registration?</h2><aside class=notes>In this workshop, we will explore fundamental concepts and practical techniques for image registration, focusing on applications in microscopy, material science, and earth science.</aside><p><img src=img/registration_big.png alt></p><h4>Spatial alignment of two or more images.</h4><ul><li>It&rsquo;s an essential step for comparing or integrating data in many scientific fields.</li></ul><aside class=notes>Image registration is the process of aligning multiple datasets into a common coordinate system, enabling accurate comparison and analysis.</aside></section><section id=section-1><h2 id=common-needs-in-research>Common needs in research</h2><div class=flex></div><div class=horizontal><p>Multimodal:
<img src=img/multimodal.jpg alt></p><p>Stitching:
<img src=img/stitching.jpg alt></p><p>Stack:
<img src=img/slice_to_slice.jpg alt></p><p>Viewpoint:
<img src=img/coregistration.jpg alt></p><p>Temporal:
<img src=img/timesteps.jpg alt></p></div><div class=flex></div><aside class=notes>Image registration is widely used across multiple disciplines.</aside><ul><li><p><strong>Microscopy</strong>: Aligning slices in a 3D stack, channels, runs, time points, tiles (stitching), and modalities.</p></li><li><p><strong>Medical Imaging</strong>: Viewpoints, stacks, normalization to an atlas, co-registering images from different modalities (e.g., MRI, CT).</p></li><li><p><strong>Earth Science</strong>: Georeferencing, integration from different sensors, aligning satellite images for change detection.</p></li><li><p><strong>Material Science</strong>: Comparing material properties under varying conditions.</p></li></ul></section><section id=section-2><h2 id=image-transformation-types>Image Transformation Types</h2><div class=flex></div><div class=horizontal><p><img src=img/transformations.png alt></p><p><img src=img/affine.png alt></p></div><div class=flex></div><p><a href=https://github.com/bellonet/image-registration-workshop/blob/main/example_notebooks/transformation_examples.ipynb>Link to: example_notebooks/transformation_examples.ipynb</a></p><aside class=notes><p>The type of transformation should be chosen based on the expected deformations in the images.<br>It&rsquo;s common to apply a more rough transformation first (e.g. affine), followed by an elastic transformation to correct for local deformations (e.g. TPS).<br>But more is not always better, as more complex transformations can lead to overfitting and with each transformation some errors are introduced (due to interpolation).</p><p>The transformation matrix can also be used to warp other channels or annotation data such as segmentation labels.</p><p>Rigid transformation requires 2 points, affine 3 points, perspective 4 points, ideally for local deformations require more.</p></aside></section><section id=section-3><h2 id=image-interpolation---reason>Image Interpolation - Reason</h2><ul><li>When we transform an image, we need to estimate pixel values at the new coordinates.</li><li>If for example, you transform an image by up-scaling it:</li></ul><p><img src=img/grids.png alt></p><ul><li>Interpolation is the process of estimating pixel values at non-integer coordinates.</li></ul></section><section id=section-4><h2 id=image-interpolation---common-types>Image Interpolation - Common Types</h2><aside class=notes>When you transform an image to a new space, you need to estimate the pixel values at the new locations.
Interpolation is used to estimate pixel values at non-integer coordinates.</aside><div class=flex></div><div class=horizontal><p><img src=img/interpolation_functions.png alt></p><p><img src=img/interpolation_weights.png alt></p></div><div class=flex></div><p>Image by <a href=https://commons.wikimedia.org/wiki/User:Cmglee>Cmglee</a>, license: CC BY-SA 4.0<br><a href=https://github.com/bellonet/image-registration-workshop/blob/main/example_notebooks/interpolation.ipynb>Link to interpolation weights and examples notebook: example_notebooks/interpolation.ipynb</a></p><aside class=notes><ul><li>Interpolation weights demo: For each interpolation type it randomly picks subpixel localization and shows weights of surrounding pixels.</li><li>Example toy image: Shows the effect of different interpolation types on a simple image.</li><li>Example of anti-aliasing when down-sampling.</li></ul></aside></section><section id=section-5><h2 id=image-interpolation-example>Image Interpolation Example</h2><p><img src=img/interpolation_rotation.png alt>
<img src=img/interpolation_shearing.png alt></p></section><section id=section-6><h2 id=image-interpolation---anti-aliasing-in-down-sampling>Image Interpolation - Anti-Aliasing in Down-Sampling</h2><p><img src=img/antialias.png alt></p><ul><li>When down-sampling an image, aliasing artifacts can occur, thus applying anti-alising filters can help to reduce these artifacts.</li><li>But, anti-aliasing filters can also blur the image, so it&rsquo;s a trade-off between sharpness and aliasing artifacts.</li></ul></section><section id=section-7><h2 id=integrated-image-registration-techniques>Integrated Image Registration Techniques</h2><aside class=notes>Introducing registration methods that combine both matching and transformation into one smooth process, simplifying image alignment.</aside><ul><li><strong>Intensity-Based Registration</strong><ul><li>Iterative process that optimizes aligned pixel intensity similarities (e.g. <strong>correlation coefficient</strong> or <strong>MSE</strong>).</li></ul></li><li><strong>Mutual Information-Based Registration</strong><ul><li>Iteratively aligns multimodal images by maximizing the statistical relationship between them.</li></ul></li><li><strong>Frequency Domain Methods</strong><ul><li>Transforms images into the Fourier space to compute alignment transformations.</li></ul></li><li><strong>Deep Learning-Based Registration</strong><ul><li>Uses neural networks to predict transformations from image data, learning complex patterns.</li></ul></li></ul></section><section id=section-8><h2 id=technique-intensity-based-correlation-coefficient>Technique: Intensity Based (Correlation Coefficient)</h2><p><img src=img/correlation_r45_s1.5.png alt>
<img src=img/correlation_r10_s1.1.png alt>
<img src=img/correlation_r2_s1.png alt>
<img src=img/correlation_r0_s1.png alt></p><aside class=notes><a href=https://github.com/bellonet/image-registration-workshop/blob/main/example_notebooks/correlation_example.ipynb>Examples were generated using: example_notebooks/correlation_example.ipynb</a></aside></section><section id=section-9><h2 id=technique-mutual-information>Technique: Mutual Information</h2><div class=flex></div><div class=horizontal><img src=img/joint_histogram_iterative.gif alt="Mutual Information iterations"><p><img src=img/hist.png alt>
<img src=img/mutual_information_equation.png alt></p></div><div class=flex></div><ul><li>Looking at the equation, the more structure we have in the joint histogram, the lower its entropy, and thus the mutual information is higher.</li></ul><aside class=notes>Entropy is maximized when there is maximum uncertainty or randomness in the pixel intensities.<br>Meaning that an image with a single pixel intensity value will have minimum entropy, and an image with a uniform distribution of pixel intensities will have maximum entropy.</aside><ul><li><a href=https://github.com/bellonet/image-registration-workshop/blob/main/example_notebooks/mutual_information.ipynb>Mutual Information implementation notebook: example_notebooks/mutual_information.ipynb</a></li></ul></section><section id=section-10><h2>2 Step Techniques - Feature Detection & Transformation</h2><aside class=notes>An overview of common methods used in image registration, highlighting the two main steps involved.</aside><p>two main steps:</p><ol><li><strong>Detecting and matching similarities</strong>: identifying corresponding regions or features<ul><li><strong>Feature-Based Registration</strong> (SIFT, SURT, ORB, BRISK, FAST)</li><li><strong>Segmentation-Based Registration</strong></li><li><strong>Model Fitting</strong></li><li><strong>Graph-Based Methods</strong></li></ul></li><li><strong>Estimating and applying transformations</strong>: Finding and applying the optimal transformation</li></ol><aside class=notes>Estimating and applying transformations will be discussed in more detail in the next slides.</aside></section><section id=section-11><h2 id=technique-feature-based-registration-sift>Technique: Feature-Based Registration (SIFT)</h2><aside class=notes>An example of applying a feature-based registration pipeline to align two images from different modalities.</aside><div class=flex></div><div class=horizontal><ol><li><strong>Detecting Similarities</strong>:<ul><li><strong>Feature Detection:</strong> Detect keypoints and their descriptors (e.g. using SIFT)</li><li><strong>Feature Matching:</strong> Match features between images to select keypoints to use.</li></ul></li><li><strong>Estimating and Applying Transformations</strong>: one image is transformed in space to match the other<ul><li><strong>Transformation Estimation:</strong> Compute transformation matrix (e.g. affine) using matched keypoints.</li><li><strong>Warping:</strong> Apply transformation to align images.</li></ul></li></ol><img src=img/sift_route.png alt="sift keypoints and matches"></div><div class=flex></div><ul><li><a href=https://github.com/bellonet/image-registration-workshop/blob/main/example_notebooks/sift_example.ipynb>SIFT based registration notebook: example_notebooks/sift_example.ipynb</a></li></ul><aside class=notes>SIFT can be robust and thus can be used for multimodal registration.</aside></section><section id=section-12><h2 id=technique-model-based-pose-estimation>Technique: Model Based (Pose Estimation)</h2><aside class=notes>In cases where many images need to be registered to the same space and pre-known features can be identified, a model-based registration pipeline can be applied.
When the relationship of the distances between the features are pre-known, similar graph-based methods can be used.
Deap learning based approaches can perform well on those tasks with minimal training data.</aside><div class=flex></div><div class=horizontal><ol><li><strong>Predefined Feature Detection</strong>: e.g. pose estimation.<ul><li><strong>Manual selection of features</strong></li><li><strong>Annotation of training data</strong></li><li><strong>Deep learning landmark detection</strong><ul><li>Model selection</li><li>training</li><li>prediction of landmark locations on all images of the dataset</li></ul></li></ul></li><li><strong>Estimating and Applying Transformations</strong> using the detected landmarks.</li></ol><p><img src=img/wing_landmarks.png alt="wing landmarks model"><img src=img/wing_registration.png alt="wing landmarks model"></p></div><div class=flex></div><aside class=notes>DeepLabCut is a tracking tool that is open-source and offer great models that can be used for pose estimation and predefined feature detection.</aside></section><section id=section-13><h2>Challenges & Considerations</h2><div class=flex></div><div class=horizontal><ul><li><strong>Method Selection</strong>:<ul><li>Match image type (e.g., multimodal) to appropriate method</li></ul></li><li><strong>Transformation Type</strong>:<ul><li>Fit transformation to deformation (e.g., rigid vs. non-rigid)</li></ul></li><li><strong>Preprocessing</strong>:<ul><li>Denoising, intensity correction, rescaling, applying filters</li><li>In hard cases - Use extrinsic information (e.g., physical landmarks)</li></ul></li></ul><p><img src=img/edge_detection.png alt></p></div><div class=flex></div><ul><li>Image source - Erik Meijering: <a href="https://www.youtube.com/watch?v=ecu8kreTwYM">https://www.youtube.com/watch?v=ecu8kreTwYM</a></li></ul></section><section id=section-14><div class=flex></div><div class=horizontal><h2 id=image-registration-guideline>Image Registration Guideline</h2><p><img src=img/flowchart.png alt="Image Registration Guideline"></p></div><div class=flex></div></section><section id=section-15><h2 id=software-tools-for-image-registration>Software Tools for Image Registration</h2><aside class=notes>Overview of common tools, libraries, and plugins for image registration.</aside><ul><li><strong>Fiji/ImageJ</strong><ul><li>Popular plugins: <strong>Feature Extraction</strong>, <strong>Warpy</strong> (QPath), <strong>TrakEM2</strong>, <strong>Register Virtual Stack Slices</strong></li></ul></li><li><strong>Python Libraries</strong><ul><li><strong>OpenCV</strong> (C++), <strong>scikit-image</strong></li></ul></li><li><strong><a href=https://elastix.dev/index.php>Elastix</a></strong><ul><li>ITKElastix (C++) is a powerful open-source tool (standalone or as a python package) for intensity-based registration.</li></ul></li><li><strong><a href=https://github.com/DeepLabCut/DeepLabCut>DeepLabCut</a></strong><ul><li>Open-source deep learning based pose estimation and model based feature detection (and tracking).</li></ul></li></ul><br><ul><li>VoltRon: R package that includes an interactive GUI for image registration.<br><a href=https://bioinformatics.mdc-berlin.de/VoltRon/index.html>https://bioinformatics.mdc-berlin.de/VoltRon/index.html</a></li><li>SIFT based image registration Python package:<br><a href=https://gitlab.com/ida-mdc/image-registration-tool>https://gitlab.com/ida-mdc/image-registration-tool</a></li></ul></section><section id=section-16><h2 id=thank-you>Thank You!</h2><h5 id=thanks-for-participating-please-feel-free-to-reach-out-with-any-questions>Thanks for participating. Please feel free to reach out with any questions.</h5><div class=flex></div><div class=horizontal><p><img src=img/people/hi-support-staff.png alt></p><p><img src=img/logos/hi.png alt></p></div><div class=flex></div><p>Contact:     <strong><a href=mailto:ella.bahry@mdc-berlin.de>ella.bahry@mdc-berlin.de</a></strong>    <strong><a href=mailto:support@helmholtz-imaging.de>support@helmholtz-imaging.de</a></strong></p><p>Presentation template: Deborah Schmidt - <a href=https://ida-mdc.gitlab.io/workshops/3d-data-visualization/>3d Data Visualization Workshop</a></p></section></div><div class=reveal-footer><span>2024</span> | <span><b>HELMHOLTZ IMAGING</b></span><span><span><a class=hidden-in-page href="?view=scroll"><strong>Exit slides</strong></a></span></span></div></div></body></html>